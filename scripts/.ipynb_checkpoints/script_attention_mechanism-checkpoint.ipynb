{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1619816813399,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "CgKbbYxJ5t8q",
    "outputId": "396983bf-e8f8-481f-ec89-4faf2b16c6bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nSanjay Singh\\nsan.singhsanjay@gmail.com\\nApril-2021\\nImplementation of Attention Mechanism for Image Captioning - Most part taken from Google Tutorials\\nImplementation of:\\nhttps://github.com/subhamio/image-captioning-using-attention-mechanism-local-attention-and-global-attention-/blob/master/image_captioning_using_attention_mechanism.ipynb\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sanjay Singh\n",
    "san.singhsanjay@gmail.com\n",
    "April-2021\n",
    "Implementation of Attention Mechanism for Image Captioning - Most part taken from Google Tutorials\n",
    "Implementation of:\n",
    "https://github.com/subhamio/image-captioning-using-attention-mechanism-local-attention-and-global-attention-/blob/master/image_captioning_using_attention_mechanism.ipynb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1864,
     "status": "ok",
     "timestamp": 1619816814051,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "MMwgVmai5_t4",
    "outputId": "18645127-7395-45f8-9e47-f8be3094556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4082,
     "status": "ok",
     "timestamp": 1619816816289,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "ZTKEHdjOASw6"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import tensorflow as tf\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from numpy import array\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import keras\n",
    "import sys, time, os, warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.utils import shuffle\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4072,
     "status": "ok",
     "timestamp": 1619816816292,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "PvEwL-9BHA0W"
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "EMBEDDING_DIM = 256\n",
    "BATCH_SIZE = 131\n",
    "BUFFER_SIZE = 1000\n",
    "UNITS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4062,
     "status": "ok",
     "timestamp": 1619816816296,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "nmqIz8RCH15E"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/image_captioning\n",
    "class VGG16_Encoder(tf.keras.Model):\n",
    "\t# This encoder passes the features through a Fully connected layer\n",
    "\tdef __init__(self, EMBEDDING_DIM):\n",
    "\t\tsuper(VGG16_Encoder, self).__init__()\n",
    "\t\tself.fc = tf.keras.layers.Dense(EMBEDDING_DIM)\n",
    "\t\tself.dropout = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)\n",
    "\tdef call(self, x):\n",
    "\t\tx = self.fc(x)\n",
    "\t\tx = tf.nn.relu(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4050,
     "status": "ok",
     "timestamp": 1619816816299,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "9SAhYeGOH7vv"
   },
   "outputs": [],
   "source": [
    "class Rnn_Local_Decoder(tf.keras.Model):\n",
    "\tdef __init__(self, embedding_dim, UNITS, vocab_size):\n",
    "\t\tsuper(Rnn_Local_Decoder, self).__init__()\n",
    "\t\tself.units = UNITS\n",
    "\t\tself.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\t\tself.gru = tf.compat.v1.keras.layers.CuDNNGRU(self.units, return_sequences=True, return_state=True,                              recurrent_initializer='glorot_uniform')\n",
    "\t\tself.fc1 = tf.keras.layers.Dense(self.units)\n",
    "\t\tself.dropout = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)\n",
    "\t\tself.batchnormalization = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\t\tself.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\t\t# Implementing Attention Mechanism\n",
    "\t\tself.Uattn = tf.keras.layers.Dense(UNITS)\n",
    "\t\tself.Wattn = tf.keras.layers.Dense(UNITS)\n",
    "\t\tself.Vattn = tf.keras.layers.Dense(1)\n",
    "\n",
    "\tdef call(self, x, features, hidden):\n",
    "\t\t# features shape ==> (64,49,256) ==> Output from ENCODER\n",
    "\t\t# hidden shape == (batch_size, hidden_size) ==>(64,512)\n",
    "\t\t# hidden_with_time_axis shape == (batch_size, 1, hidden_size) ==> (64,1,512)\n",
    "\t\thidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\t\t# score shape == (64, 49, 1)\n",
    "\t\t# Attention Function\n",
    "\t\t'''e(ij) = f(s(t-1),h(j))'''\n",
    "\t\t''' e(ij) = Vattn(T)*tanh(Uattn * h(j) + Wattn * s(t))'''\n",
    "\t\tscore = self.Vattn(tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis)))\n",
    "\t\t# self.Uattn(features) : (64,49,512)\n",
    "\t\t# self.Wattn(hidden_with_time_axis) : (64,1,512)\n",
    "\t\t# tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis)) : (64,49,512)\n",
    "\t\t# self.Vattn(tf.nn.tanh(self.Uattn(features) + self.Wattn(hidden_with_time_axis))) : (64,49,1) ==> score\n",
    "\t\t# you get 1 at the last axis because you are applying score to self.Vattn\n",
    "\t\t# Then find Probability using Softmax\n",
    "\t\t'''attention_weights(alpha(ij)) = softmax(e(ij))'''\n",
    "\t\tattention_weights = tf.nn.softmax(score, axis=1)\n",
    "\t\t# attention_weights shape == (64, 49, 1)\n",
    "\t\t# Give weights to the different pixels in the image\n",
    "\t\t''' C(t) = Summation(j=1 to T) (attention_weights * VGG-16 features) '''\n",
    "\t\tcontext_vector = attention_weights * features\n",
    "\t\tcontext_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\t\t# Context Vector(64,256) = AttentionWeights(64,49,1) * features(64,49,256)\n",
    "\t\t# context_vector shape after sum == (64, 256)\n",
    "\t\t# x shape after passing through embedding == (64, 1, 256)\n",
    "\t\tx = self.embedding(x)\n",
    "\t\t# x shape after concatenation == (64, 1,  512)\n",
    "\t\tx = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\t\t# passing the concatenated vector to the GRU\n",
    "\t\toutput, state = self.gru(x)\n",
    "\t\t# shape == (batch_size, max_length, hidden_size)\n",
    "\t\tx = self.fc1(output)\n",
    "\t\t# x shape == (batch_size * max_length, hidden_size)\n",
    "\t\tx = tf.reshape(x, (-1, x.shape[2]))\n",
    "\t\t# Adding Dropout and BatchNorm Layers\n",
    "\t\tx= self.dropout(x)\n",
    "\t\tx= self.batchnormalization(x)\n",
    "\t\t# output shape == (64 * 512)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\t# shape : (64 * 8329(vocab))\n",
    "\t\treturn x, state, attention_weights\n",
    "\n",
    "\tdef reset_state(self, batch_size):\n",
    "\t\treturn tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4041,
     "status": "ok",
     "timestamp": 1619816816302,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0B9aUr_2IAYV"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "\tmask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "\tloss_ = loss_object(real, pred)\n",
    "\tmask = tf.cast(mask, dtype=loss_.dtype)\n",
    "\tloss_ *= mask\n",
    "\treturn tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4028,
     "status": "ok",
     "timestamp": 1619816816303,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "LY8XNty0IETK"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "\tloss = 0\n",
    "\t# initializing the hidden state for each batch\n",
    "\t# because the captions are not related from image to image\n",
    "\thidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\tdec_input = tf.expand_dims([wordtoix['startseq']] * BATCH_SIZE, 1)\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tfeatures = encoder(img_tensor)\n",
    "\t\tfor i in range(1, target.shape[1]):\n",
    "\t\t\t# passing the features through the decoder\n",
    "\t\t\tpredictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "\t\t\tloss += loss_function(target[:, i], predictions)\n",
    "\t\t\t# using teacher forcing\n",
    "\t\t\tdec_input = tf.expand_dims(target[:, i], 1)\n",
    "\ttotal_loss = (loss / int(target.shape[1]))\n",
    "\ttrainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\tgradients = tape.gradient(loss, trainable_variables)\n",
    "\toptimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\treturn loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4019,
     "status": "ok",
     "timestamp": 1619816816305,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "13LIAyZuIIt1"
   },
   "outputs": [],
   "source": [
    "# function to read, resize and preprocess an image\n",
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = preprocess_input(img)\n",
    "    return img, image_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4006,
     "status": "ok",
     "timestamp": 1619816816306,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "CEgBBBu7INJM"
   },
   "outputs": [],
   "source": [
    "def map_func(img_name, cap):\n",
    "\timg_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
    "\treturn img_tensor, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3987,
     "status": "ok",
     "timestamp": 1619816816309,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "55Tl9qX9IQb4"
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "images_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/train_npy_files/\"\n",
    "img_captions_csv_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data_AttentionMech/train_image_caption_processed.csv\"\n",
    "vocabulary_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data_AttentionMech/vocabulary.txt\"\n",
    "max_caption_len_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data_AttentionMech/max_caption_length.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3973,
     "status": "ok",
     "timestamp": 1619816816310,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "nmTtV8YMIUQb"
   },
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "data = pd.read_csv(img_captions_csv_path)\n",
    "img_name = list(data['image'])\n",
    "img_caption = list(data['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3961,
     "status": "ok",
     "timestamp": 1619816816312,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "hBsiooRXIZNo"
   },
   "outputs": [],
   "source": [
    "# appending image names to their paths\n",
    "for i in range(len(img_name)):\n",
    "\timg_name[i] = images_path + img_name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1619816816315,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "bOjBkjNMIc_q"
   },
   "outputs": [],
   "source": [
    "# reading vocabulary file\n",
    "vocabulary = list()\n",
    "f_ptr = open(vocabulary_path, \"r\")\n",
    "lines = f_ptr.readlines()\n",
    "for line in lines:\n",
    "\tvocabulary.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3927,
     "status": "ok",
     "timestamp": 1619816816317,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0q2-rZk_IuMg",
    "outputId": "7e1d0430-7566-4444-f27e-713d214f296a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  1657\n"
     ]
    }
   ],
   "source": [
    "# finding size of vocabulary\n",
    "vocab_size = len(vocabulary) + 1 # added 1 for padded zero\n",
    "print(\"Vocabulary Size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3904,
     "status": "ok",
     "timestamp": 1619816816319,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "5-krs1w8Ixx8"
   },
   "outputs": [],
   "source": [
    "# making word-to-index and index-to-word dictionary\n",
    "wordtoix = dict()\n",
    "ixtoword = dict()\n",
    "for i in range(len(vocabulary)):\n",
    "\twordtoix[vocabulary[i]] = (i + 1)\n",
    "\tixtoword[(i + 1)] = vocabulary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3889,
     "status": "ok",
     "timestamp": 1619816816321,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "9sQsht1PI2Rf",
    "outputId": "d10630c3-8d90-4ee9-b8ad-14915fbe29f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Caption Length:  31\n"
     ]
    }
   ],
   "source": [
    "# finding max caption length\n",
    "f_ptr = open(max_caption_len_path, 'r')\n",
    "data = f_ptr.read()\n",
    "f_ptr.close()\n",
    "max_caption_len = int(data.split(\":\")[1].strip())\n",
    "print(\"Max Caption Length: \", max_caption_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3867,
     "status": "ok",
     "timestamp": 1619816816323,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "xsDqz0oaI529",
    "outputId": "394b5270-db6a-49c3-8add-c0451a7f008c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all_img_names:  29999\n",
      "Length of all_captions:  29999\n"
     ]
    }
   ],
   "source": [
    "# converting captions to their indices\n",
    "all_img_names = list()\n",
    "all_captions = list()\n",
    "img_caption_ix = list()\n",
    "for i in range(len(img_caption)):\n",
    "\tcaptions = img_caption[i].split(\"#\")\n",
    "\tfor caption in captions:\n",
    "\t\tall_img_names.append(img_name[i])\n",
    "\t\tall_captions.append(caption)\n",
    "\t\twords = caption.split(\" \")\n",
    "\t\ttemp_list = list()\n",
    "\t\tfor word in words:\n",
    "\t\t\tif(word in wordtoix):\n",
    "\t\t\t\ttemp_list.append(wordtoix[word])\n",
    "\t\timg_caption_ix.append(temp_list)\n",
    "# printing shape of all_img_names and all_captions\n",
    "print(\"Length of all_img_names: \", len(all_img_names))\n",
    "print(\"Length of all_captions: \", len(all_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3844,
     "status": "ok",
     "timestamp": 1619816816326,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "2P2tGjIUI9VL",
    "outputId": "bb99318a-10ef-40fb-88b6-496780ab86ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of img_caption_padded:  (29999, 31)\n"
     ]
    }
   ],
   "source": [
    "# padding zeros to each caption to make it equal to max_caption_len\n",
    "img_caption_padded = tf.keras.preprocessing.sequence.pad_sequences(img_caption_ix, max_caption_len, padding='post')\n",
    "print(\"Shape of img_caption_padded: \", img_caption_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5270,
     "status": "ok",
     "timestamp": 1619816817777,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "350YZjqJJEZW"
   },
   "outputs": [],
   "source": [
    "# loading vgg-16 model to extract bottleneck features\n",
    "image_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 5253,
     "status": "ok",
     "timestamp": 1619816817780,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "n91KTNQ9JHrE",
    "outputId": "f9b4157c-746b-4d86-f569-553b0c107c07"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# to map data to loading function - to create npy files\\nencode_train = sorted(set(img_name))\\nimage_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\\nimage_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\\n\\n# saving npy files\\nfor img, path in tqdm(image_dataset):\\n\\tbatch_features = image_features_extract_model(img) # batch_features.shape: [BATCH_SIZE, 7, 7, 512]\\n\\tbatch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3])) # batch_features.shape: [BATCH_SIZE, 49, 512]\\n\\tfor bf, p in zip(batch_features, path):\\n\\t\\tpath_of_feature = p.numpy().decode(\"utf-8\")\\n\\t\\tnp.save(path_of_feature, bf.numpy())\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# to map data to loading function - to create npy files\n",
    "encode_train = sorted(set(img_name))\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
    "image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "# saving npy files\n",
    "for img, path in tqdm(image_dataset):\n",
    "\tbatch_features = image_features_extract_model(img) # batch_features.shape: [BATCH_SIZE, 7, 7, 512]\n",
    "\tbatch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3])) # batch_features.shape: [BATCH_SIZE, 49, 512]\n",
    "\tfor bf, p in zip(batch_features, path):\n",
    "\t\tpath_of_feature = p.numpy().decode(\"utf-8\")\n",
    "\t\tnp.save(path_of_feature, bf.numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 5239,
     "status": "ok",
     "timestamp": 1619816817784,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "AJfbd79iJLoo"
   },
   "outputs": [],
   "source": [
    "# defining optimization and loss-object\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5231,
     "status": "ok",
     "timestamp": 1619816817787,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "0t95e67JJoXX"
   },
   "outputs": [],
   "source": [
    "# making image and caption map - for training\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_img_names, img_caption_padded))\n",
    "dataset = dataset.map(lambda item1, item2: tf.numpy_function(map_func, [item1, item2], [tf.float32, tf.int32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1619816817790,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "axHZcVYDJq3G"
   },
   "outputs": [],
   "source": [
    "# defining encoder and decoder\n",
    "encoder = VGG16_Encoder(EMBEDDING_DIM)\n",
    "decoder = Rnn_Local_Decoder(EMBEDDING_DIM, UNITS, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5207,
     "status": "ok",
     "timestamp": 1619816817794,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "j0pz6tAbJumO",
    "outputId": "8148d30c-76ab-41d6-8778-e033b51699da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_steps:  229\n"
     ]
    }
   ],
   "source": [
    "# defining num_steps \n",
    "num_steps = len(all_img_names) // BATCH_SIZE\n",
    "print(\"num_steps: \", num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 858550,
     "status": "ok",
     "timestamp": 1619817671166,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "4dl4ozmGJxGH",
    "outputId": "a1558263-ae42-4ead-b855-770754d51eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch-1 and batch-1: 22.46990442276001 sec, Loss: 2.2415020850396927\n",
      "\n",
      "Time taken for epoch-1 and batch-101: 40.396193981170654 sec, Loss: 1.4331924684586064\n",
      "\n",
      "Time taken for epoch-1 and batch-201: 58.300397872924805 sec, Loss: 1.3033741366478704\n",
      "\n",
      "Epoch 1 Loss 1.428742\n",
      "Time taken for 1 epoch 62.9291877746582 sec\n",
      "\n",
      "Time taken for epoch-2 and batch-1: 1.2008726596832275 sec, Loss: 1.209778078140751\n",
      "\n",
      "Time taken for epoch-2 and batch-101: 19.19206929206848 sec, Loss: 1.134524929908014\n",
      "\n",
      "Time taken for epoch-2 and batch-201: 37.11392569541931 sec, Loss: 1.1454983372842111\n",
      "\n",
      "Epoch 2 Loss 1.109071\n",
      "Time taken for 1 epoch 41.70030665397644 sec\n",
      "\n",
      "Time taken for epoch-3 and batch-1: 1.2028591632843018 sec, Loss: 1.1055418445217995\n",
      "\n",
      "Time taken for epoch-3 and batch-101: 18.98026704788208 sec, Loss: 1.0486766446021296\n",
      "\n",
      "Time taken for epoch-3 and batch-201: 36.8588342666626 sec, Loss: 1.0149089444068171\n",
      "\n",
      "Epoch 3 Loss 1.005771\n",
      "Time taken for 1 epoch 41.48889517784119 sec\n",
      "\n",
      "Time taken for epoch-4 and batch-1: 1.1885771751403809 sec, Loss: 0.9849222244754914\n",
      "\n",
      "Time taken for epoch-4 and batch-101: 19.21122908592224 sec, Loss: 0.913664787046371\n",
      "\n",
      "Time taken for epoch-4 and batch-201: 36.992432594299316 sec, Loss: 0.8928578284478956\n",
      "\n",
      "Epoch 4 Loss 0.936169\n",
      "Time taken for 1 epoch 41.58589839935303 sec\n",
      "\n",
      "Time taken for epoch-5 and batch-1: 1.22035551071167 sec, Loss: 0.9294919044740738\n",
      "\n",
      "Time taken for epoch-5 and batch-101: 19.219409704208374 sec, Loss: 0.8642624885805191\n",
      "\n",
      "Time taken for epoch-5 and batch-201: 37.004037380218506 sec, Loss: 0.8710164716166835\n",
      "\n",
      "Epoch 5 Loss 0.881170\n",
      "Time taken for 1 epoch 41.66939306259155 sec\n",
      "\n",
      "Time taken for epoch-6 and batch-1: 1.2353579998016357 sec, Loss: 0.8416786193847656\n",
      "\n",
      "Time taken for epoch-6 and batch-101: 19.283052682876587 sec, Loss: 0.8753468298142956\n",
      "\n",
      "Time taken for epoch-6 and batch-201: 37.111560106277466 sec, Loss: 0.839171624952747\n",
      "\n",
      "Epoch 6 Loss 0.834397\n",
      "Time taken for 1 epoch 41.684582471847534 sec\n",
      "\n",
      "Time taken for epoch-7 and batch-1: 1.2159397602081299 sec, Loss: 0.8200633141302294\n",
      "\n",
      "Time taken for epoch-7 and batch-101: 18.976569414138794 sec, Loss: 0.8521681139546056\n",
      "\n",
      "Time taken for epoch-7 and batch-201: 36.861491441726685 sec, Loss: 0.7849399197486139\n",
      "\n",
      "Epoch 7 Loss 0.792829\n",
      "Time taken for 1 epoch 41.495150566101074 sec\n",
      "\n",
      "Time taken for epoch-8 and batch-1: 1.1879644393920898 sec, Loss: 0.7499576691658266\n",
      "\n",
      "Time taken for epoch-8 and batch-101: 19.095010995864868 sec, Loss: 0.7400607447470388\n",
      "\n",
      "Time taken for epoch-8 and batch-201: 36.98033094406128 sec, Loss: 0.7303379428002142\n",
      "\n",
      "Epoch 8 Loss 0.754435\n",
      "Time taken for 1 epoch 41.57034420967102 sec\n",
      "\n",
      "Time taken for epoch-9 and batch-1: 1.1893939971923828 sec, Loss: 0.7370818353468372\n",
      "\n",
      "Time taken for epoch-9 and batch-101: 19.091013431549072 sec, Loss: 0.7626088050103956\n",
      "\n",
      "Time taken for epoch-9 and batch-201: 36.79720687866211 sec, Loss: 0.7428870662566154\n",
      "\n",
      "Epoch 9 Loss 0.720703\n",
      "Time taken for 1 epoch 41.420008182525635 sec\n",
      "\n",
      "Time taken for epoch-10 and batch-1: 1.2030954360961914 sec, Loss: 0.7501719074864541\n",
      "\n",
      "Time taken for epoch-10 and batch-101: 18.965484857559204 sec, Loss: 0.7464156612273185\n",
      "\n",
      "Time taken for epoch-10 and batch-201: 36.69989800453186 sec, Loss: 0.6601229021626134\n",
      "\n",
      "Epoch 10 Loss 0.688697\n",
      "Time taken for 1 epoch 41.316415786743164 sec\n",
      "\n",
      "Time taken for epoch-11 and batch-1: 1.2224342823028564 sec, Loss: 0.6936298493416079\n",
      "\n",
      "Time taken for epoch-11 and batch-101: 19.068481922149658 sec, Loss: 0.6733815593104209\n",
      "\n",
      "Time taken for epoch-11 and batch-201: 37.037312269210815 sec, Loss: 0.6929849193942162\n",
      "\n",
      "Epoch 11 Loss 0.660371\n",
      "Time taken for 1 epoch 41.69329118728638 sec\n",
      "\n",
      "Time taken for epoch-12 and batch-1: 1.2056431770324707 sec, Loss: 0.6279447001795615\n",
      "\n",
      "Time taken for epoch-12 and batch-101: 19.066656589508057 sec, Loss: 0.6396485605547505\n",
      "\n",
      "Time taken for epoch-12 and batch-201: 36.81794714927673 sec, Loss: 0.6322265748054751\n",
      "\n",
      "Epoch 12 Loss 0.633810\n",
      "Time taken for 1 epoch 41.40742015838623 sec\n",
      "\n",
      "Time taken for epoch-13 and batch-1: 1.2127327919006348 sec, Loss: 0.6408794772240424\n",
      "\n",
      "Time taken for epoch-13 and batch-101: 19.086496114730835 sec, Loss: 0.6352309565390309\n",
      "\n",
      "Time taken for epoch-13 and batch-201: 36.945308208465576 sec, Loss: 0.6107427535518524\n",
      "\n",
      "Epoch 13 Loss 0.607607\n",
      "Time taken for 1 epoch 41.580204010009766 sec\n",
      "\n",
      "Time taken for epoch-14 and batch-1: 1.1901218891143799 sec, Loss: 0.5681312314925655\n",
      "\n",
      "Time taken for epoch-14 and batch-101: 19.030577898025513 sec, Loss: 0.6180550975184287\n",
      "\n",
      "Time taken for epoch-14 and batch-201: 37.92170810699463 sec, Loss: 0.584274415046938\n",
      "\n",
      "Epoch 14 Loss 0.583265\n",
      "Time taken for 1 epoch 42.607117652893066 sec\n",
      "\n",
      "Time taken for epoch-15 and batch-1: 1.2114169597625732 sec, Loss: 0.6003933568154612\n",
      "\n",
      "Time taken for epoch-15 and batch-101: 19.036428213119507 sec, Loss: 0.5537569599766885\n",
      "\n",
      "Time taken for epoch-15 and batch-201: 36.83427119255066 sec, Loss: 0.5748652796591481\n",
      "\n",
      "Epoch 15 Loss 0.560865\n",
      "Time taken for 1 epoch 41.54032611846924 sec\n",
      "\n",
      "Time taken for epoch-16 and batch-1: 1.191676378250122 sec, Loss: 0.5652611024918095\n",
      "\n",
      "Time taken for epoch-16 and batch-101: 19.157564163208008 sec, Loss: 0.589234875094506\n",
      "\n",
      "Time taken for epoch-16 and batch-201: 37.000195026397705 sec, Loss: 0.5286467152257119\n",
      "\n",
      "Epoch 16 Loss 0.540590\n",
      "Time taken for 1 epoch 41.615052938461304 sec\n",
      "\n",
      "Time taken for epoch-17 and batch-1: 1.2480602264404297 sec, Loss: 0.5391997675741872\n",
      "\n",
      "Time taken for epoch-17 and batch-101: 19.01720118522644 sec, Loss: 0.5121207083425214\n",
      "\n",
      "Time taken for epoch-17 and batch-201: 36.81451439857483 sec, Loss: 0.5396963550198463\n",
      "\n",
      "Epoch 17 Loss 0.520692\n",
      "Time taken for 1 epoch 41.460567474365234 sec\n",
      "\n",
      "Time taken for epoch-18 and batch-1: 1.2604763507843018 sec, Loss: 0.5396990006969821\n",
      "\n",
      "Time taken for epoch-18 and batch-101: 19.165968656539917 sec, Loss: 0.5397945527107485\n",
      "\n",
      "Time taken for epoch-18 and batch-201: 37.00944495201111 sec, Loss: 0.5194556943831905\n",
      "\n",
      "Epoch 18 Loss 0.501490\n",
      "Time taken for 1 epoch 41.59951043128967 sec\n",
      "\n",
      "Time taken for epoch-19 and batch-1: 1.233036994934082 sec, Loss: 0.4999419489214497\n",
      "\n",
      "Time taken for epoch-19 and batch-101: 19.02323842048645 sec, Loss: 0.48070421526508944\n",
      "\n",
      "Time taken for epoch-19 and batch-201: 36.93465209007263 sec, Loss: 0.4804319566295993\n",
      "\n",
      "Epoch 19 Loss 0.483977\n",
      "Time taken for 1 epoch 41.56733226776123 sec\n",
      "\n",
      "Time taken for epoch-20 and batch-1: 1.1997451782226562 sec, Loss: 0.47721090624409335\n",
      "\n",
      "Time taken for epoch-20 and batch-101: 19.024826288223267 sec, Loss: 0.5036955495034495\n",
      "\n",
      "Time taken for epoch-20 and batch-201: 36.76341438293457 sec, Loss: 0.4642217697635774\n",
      "\n",
      "Epoch 20 Loss 0.468315\n",
      "Time taken for 1 epoch 41.48344898223877 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training related parameters and training\n",
    "loss_plot = []\n",
    "start_epoch = 0\n",
    "EPOCHS = 20\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        #target = tf.reshape(target, (1, target.shape[0]))\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "        if batch % 100 == 0:\n",
    "            print(\"Time taken for epoch-{} and batch-{}: {} sec, Loss: {}\\n\".format(epoch + 1, batch + 1, time.time() - start, batch_loss.numpy() / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1, total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1619818050067,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "MRTiWDumqIUb",
    "outputId": "afcc94d4-50f2-4a0a-8cfc-fc42ea75f60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f53111406d0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/encoder_May1/assets\n"
     ]
    }
   ],
   "source": [
    "encoder.save(\"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/encoder_May1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 1162,
     "status": "error",
     "timestamp": 1619818120582,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "yVvhWcG3rpIN",
    "outputId": "704833ae-1988-44c2-efa1-b259d0611275"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9dfb89cfa04b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/decoder_May1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2002\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 157\u001b[0;31m                           signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m   _, exported_graph, object_saver, asset_info = _build_meta_graph(\n\u001b[0;32m-> 1033\u001b[0;31m       obj, signatures, options, meta_graph_def)\n\u001b[0m\u001b[1;32m   1034\u001b[0m   \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_schema_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_SCHEMA_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     signatures = signature_serialization.find_function_to_export(\n\u001b[0;32m-> 1133\u001b[0;31m         checkpoint_graph_view)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m   signatures, wrapped_functions = (\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;31m# If the user did not specify signatures, check the root object for a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;31m# that can be made into a signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SIGNATURE_ATTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj, extra_functions)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0;32m--> 151\u001b[0;31m           self._serialization_cache)\n\u001b[0m\u001b[1;32m    152\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m     functions = super(\n\u001b[0;32m-> 2613\u001b[0;31m         Model, self)._list_functions_for_serialization(serialization_cache)\n\u001b[0m\u001b[1;32m   2614\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   3085\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 3087\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     return (self._get_serialized_attributes(\n\u001b[0;32m---> 79\u001b[0;31m         serialization_cache).functions_to_serialize)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_serialized_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 95\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# cache (i.e. this is the root level object).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKERAS_CACHE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mdefault_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_save_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Other than the default signature function, all other attributes match with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mdefault_save_signature\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_model_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m   \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0mconcrete\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \"\"\"\n\u001b[0;32m-> 1299\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36m_wrapped_model\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    133\u001b[0m     with base_layer_utils.call_context().enter(\n\u001b[1;32m    134\u001b[0m         model, inputs=inputs, build_graph=False, training=False, saving=True):\n\u001b[0;32m--> 135\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Outputs always has to be a flat dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: call() missing 2 required positional arguments: 'features' and 'hidden'"
     ]
    }
   ],
   "source": [
    "decoder.save(\"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/decoder_May1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1619818480798,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "AKuLFXhhtG1X",
    "outputId": "6e4aba22-4c9f-44c3-9dcf-f05178475d81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/ckpt-1'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/attention_mech_models/\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,decoder=decoder,optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt_manager.save()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKlrRpUdZZElZ5E9r5M3H6",
   "collapsed_sections": [],
   "name": "script_attention_mechanism.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
