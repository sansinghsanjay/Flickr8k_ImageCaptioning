{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1619104778116,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "Sz0Ng-UCFWc2",
    "outputId": "2640c7a3-ba85-46af-cd77-d8d7b6a8f6e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nSanjay Singh\\nsan.singhsanjay@gmail.com\\nApril-2021\\nTo train a neural network for Image Captioning - on Google Colab\\nThis script file is copy of script_training.py, only paths have changed in this file to make it to work on Google Colab\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sanjay Singh\n",
    "san.singhsanjay@gmail.com\n",
    "April-2021\n",
    "To train a neural network for Image Captioning - on Google Colab\n",
    "This script file is copy of script_training.py, only paths have changed in this file to make it to work on Google Colab\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1619104781379,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "lzqmLeFQHvwK",
    "outputId": "8839dd52-1e36-4d5e-f98c-f35ab2107827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# start by connecting gdrive into the google colab\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1619112152828,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "Ta63BKv9FnRI"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blnZBsUaFtLN"
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "EPOCHS = 20\n",
    "NUMBER_PICS_PER_BATCH = 3\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HyMpXuOFxRB"
   },
   "outputs": [],
   "source": [
    "# function to update status\n",
    "def percentage_progress(completed, total):\n",
    "\tperc_progress = (completed / total) * 100\n",
    "\tperc_progress = round(perc_progress, 2)\n",
    "\treturn perc_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_efLZZUzF0LH"
   },
   "outputs": [],
   "source": [
    "# data generator function\n",
    "'''\n",
    "To run parts of this function in ipython without calling function\n",
    "image_name_captions = train_image_caption\n",
    "image_features = train_image_feature\n",
    "num_pics_per_batch = NUMBER_PICS_PER_BATCH\n",
    "'''\n",
    "def data_generator(image_name_captions, image_features, wordtoix, max_caption_length, vocab_size, num_pics_per_batch):\n",
    "\tX1, X2, y = list(), list(), list()\n",
    "\tn = 0\n",
    "\twhile(True):\n",
    "\t\tfor i in range(image_name_captions.shape[0]):\n",
    "\t\t\tn += 1\n",
    "\t\t\timage_name = image_name_captions.iloc[i]['image']\n",
    "\t\t\timage_feature = image_features[image_name]\n",
    "\t\t\tcaptions = image_name_captions.iloc[i]['caption']\n",
    "\t\t\tcaptions_list = captions.split(\"#\")\n",
    "\t\t\tfor caption in captions_list:\n",
    "\t\t\t\tseq = [wordtoix[word] for word in caption.split(' ') if word in wordtoix]\n",
    "\t\t\t\tfor j in range(len(seq)):\n",
    "\t\t\t\t\tin_seq, out_seq = seq[:j], seq[j]\n",
    "\t\t\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_caption_length, padding='post')[0]\n",
    "\t\t\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\t\t\t\t\tX1.append(image_feature)\n",
    "\t\t\t\t\tX2.append(in_seq)\n",
    "\t\t\t\t\ty.append(out_seq)\n",
    "\t\t\tif(n == num_pics_per_batch):\n",
    "\t\t\t\tyield [array(X1), array(X2)], array(y)\n",
    "\t\t\t\tX1, X2, y = list(), list(), list()\n",
    "\t\t\t\tn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rgj4eMtIF4Cz"
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "train_image_caption_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data/train_image_caption_processed.csv\"\n",
    "train_image_bottleneck_feature_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data/train_imagename_bottleneck_feat.csv\"\n",
    "vocabulary_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data/vocabulary.txt\"\n",
    "glove_model_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/pre-trained_models/glove.6B.200d.txt\"\n",
    "max_caption_length_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/processed_data/max_caption_length.txt\"\n",
    "target_path = \"/content/gdrive/MyDrive/Flickr8k_ImageCaptioning/output/trained_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1619104805019,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "F4WXkfd4F7uw",
    "outputId": "a9d62619-4498-44cd-84f0-25a1ab51755b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed reading vocabulary file\n"
     ]
    }
   ],
   "source": [
    "# reading vocabulary\n",
    "vocabulary = list()\n",
    "f_ptr = open(vocabulary_path, 'r')\n",
    "lines = f_ptr.readlines()\n",
    "for line in lines:\n",
    "\tvocabulary.append(line.strip())\n",
    "print(\"Completed reading vocabulary file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1619104808820,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "rOAyCX23GBEX",
    "outputId": "f184f685-0eac-42d0-8772-34443686703b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created word-to-index and index-to-word dictionary\n"
     ]
    }
   ],
   "source": [
    "# creating word-to-index and index-to word dictionary\n",
    "wordtoix = dict()\n",
    "ixtoword = dict()\n",
    "#ix = 1\n",
    "for i in range(len(vocabulary)):\n",
    "\twordtoix[vocabulary[i]] = i\n",
    "\tixtoword[i] = vocabulary[i]\n",
    "\t#ix += 1\n",
    "print(\"Created word-to-index and index-to-word dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1554,
     "status": "ok",
     "timestamp": 1619111111036,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "NzGZxdXFfVsJ",
    "outputId": "44460a38-0c8c-4620-ba26-64ef9c61f5ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordtoix svaed as csv file\n"
     ]
    }
   ],
   "source": [
    "# saving wordtoix as csv file\n",
    "f_ptr = open(target_path + \"wordtoix.csv\", \"w\")\n",
    "for key, value in wordtoix.items():\n",
    "  f_ptr.write(str(key) + \",\" + str(value) + \"\\n\")\n",
    "f_ptr.close()\n",
    "print(\"wordtoix saved as csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1619111320159,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "U6f0tLmMi6Oe",
    "outputId": "c16c75c8-e7ae-4073-9399-527ef9f6bf66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ixtoword saved as csv file\n"
     ]
    }
   ],
   "source": [
    "# saving ixtoword as csv file\n",
    "f_ptr = open(target_path + \"ixtoword.csv\", \"w\")\n",
    "for key, value in ixtoword.items():\n",
    "  f_ptr.write(str(key) + \",\" + str(value) + \"\\n\")\n",
    "f_ptr.close()\n",
    "print(\"ixtoword saved as csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1619104812981,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "15B4PhG0GE5c",
    "outputId": "90d09bf4-1118-409b-f164-5065dd321716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  1652\n"
     ]
    }
   ],
   "source": [
    "# getting vocabulary size\n",
    "vocab_size = len(wordtoix) + 1 # 1 is added for '0'\n",
    "print(\"Vocabulary Size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14780,
     "status": "ok",
     "timestamp": 1619104829338,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "JZU6L2bLGIbY",
    "outputId": "dfaad6ce-f4a3-4792-b1ff-fbed67209487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe model\n"
     ]
    }
   ],
   "source": [
    "# loading GloVe model\n",
    "glove_model = dict()\n",
    "glove_data = open(glove_model_path, encoding='utf-8')\n",
    "for line in glove_data:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tfeat = values[1:]\n",
    "\tglove_model[word] = feat\n",
    "print(\"Loaded GloVe model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1289,
     "status": "ok",
     "timestamp": 1619104897837,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "tkKJvSuDGL22",
    "outputId": "d5dbd8a2-c490-4096-f4ac-ad29e3904729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Embedding Matrix, i.e., GloVe bottleneck features for each word of vocabulary\n"
     ]
    }
   ],
   "source": [
    "# creating embedding matrix, i.e., glove feature for each word in vocabulary\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM)) \n",
    "for i in range(len(vocabulary)):\n",
    "\tembedding_vec = glove_model.get(vocabulary[i])\n",
    "\tif(embedding_vec is not None):\n",
    "\t\tembedding_matrix[i] = embedding_vec\n",
    "print(\"Successfully created Embedding Matrix, i.e., GloVe bottleneck features for each word of vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1619112261621,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "ajzUMH5QmenX",
    "outputId": "24c8eea2-18bd-4a55-b1fb-cb7805564edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved embedding_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "# saving embedding_matrix\n",
    "savetxt(target_path + \"embedding_matrix.csv\", embedding_matrix, delimiter=',')\n",
    "print(\"Successfully saved embedding_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1619104901303,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "TFiSgoA5GPKv",
    "outputId": "bba89749-f624-4181-b812-ce1e05f3aa39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read training - image name and processed caption file\n"
     ]
    }
   ],
   "source": [
    "# reading training file (image name and processed captions)\n",
    "train_image_caption = pd.read_csv(train_image_caption_path)\n",
    "print(\"Successfully read training - image name and processed caption file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4182,
     "status": "ok",
     "timestamp": 1619104906204,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "sH1CxYFsGSI2",
    "outputId": "3a2034e8-5846-44f6-8597-d5aaba5fb55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully read training - image name and their InceptionV3 bottleneck feature file\n"
     ]
    }
   ],
   "source": [
    "# reading training - image name and bottleneck feature file\n",
    "train_image_feature = pd.read_csv(train_image_bottleneck_feature_path)\n",
    "print(\"Sucessfully read training - image name and their InceptionV3 bottleneck feature file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3454,
     "status": "ok",
     "timestamp": 1619104910386,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "_C2F-mNtGVY8",
    "outputId": "58783e2a-6812-4e7f-ea54-f28a5dd827da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting training - image name and feature from dataframe to dicitonary for quick search. Wait...\n",
      "Successfully converted training - image name and feature from dataframe to dictionary\n"
     ]
    }
   ],
   "source": [
    "# converting train_image_feature dataframe to dictionary\n",
    "print(\"Converting training - image name and feature from dataframe to dicitonary for quick search. Wait...\")\n",
    "train_image_feature = train_image_feature.set_index('image').T.to_dict('list')\n",
    "print(\"Successfully converted training - image name and feature from dataframe to dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x54Y-rajGY7b"
   },
   "outputs": [],
   "source": [
    "# steps required for training\n",
    "steps = (train_image_caption.shape[0]) // NUMBER_PICS_PER_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSPlbsXUGb7W"
   },
   "outputs": [],
   "source": [
    "# extract maximum length of caption - saved by script_preprocessing.py\n",
    "f_ptr = open(max_caption_length_path, 'r')\n",
    "line = f_ptr.readlines()\n",
    "max_caption_length = int(line[0].split(\":\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvamdU_ZGe2a"
   },
   "outputs": [],
   "source": [
    "# defining model\n",
    "inputs1 = Input(shape=(2048,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "inputs2 = Input(shape=(max_caption_length,))\n",
    "se1 = Embedding(vocab_size, EMBEDDING_DIM, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1619104922549,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "3Lpv5UdiGjcd",
    "outputId": "508fcd95-3265-49bd-d993-de8a7ce626b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 28, 200)      330400      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          467968      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1652)         424564      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,813,268\n",
      "Trainable params: 1,813,268\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75wE8v46Gove"
   },
   "outputs": [],
   "source": [
    "# use embedding matrix as weights in layer 2\n",
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3238269,
     "status": "ok",
     "timestamp": 1619108188711,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "xXDDGZ9OG1N5",
    "outputId": "f3812c8c-e8e8-4545-da77-b6bb3bc875a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 164s 80ms/step - loss: 4.3612\n",
      "2000/2000 [==============================] - 163s 81ms/step - loss: 3.2361\n",
      "2000/2000 [==============================] - 164s 82ms/step - loss: 3.0189\n",
      "2000/2000 [==============================] - 164s 82ms/step - loss: 2.8888\n",
      "2000/2000 [==============================] - 163s 82ms/step - loss: 2.8000\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.7315\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.6772\n",
      "2000/2000 [==============================] - 161s 81ms/step - loss: 2.6354\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.5992\n",
      "2000/2000 [==============================] - 161s 80ms/step - loss: 2.5712\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.5442\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.5183\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.5021\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.4829\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.4654\n",
      "2000/2000 [==============================] - 161s 81ms/step - loss: 2.4504\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.4368\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.4250\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 2.4140\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 2.4035\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "for i in range(EPOCHS):\n",
    "\tgenerator = data_generator(train_image_caption, train_image_feature, wordtoix, max_caption_length, vocab_size, NUMBER_PICS_PER_BATCH)\n",
    "\tmodel.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "\tmodel.save(target_path + 'model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_m0KYdAYAkF"
   },
   "outputs": [],
   "source": [
    "# tuning learning rate\n",
    "model.optimizer.lr = 0.0001\n",
    "NEW_EPOCHS = 10\n",
    "NEW_NUMBER_PICS_PER_BATCH = 6\n",
    "steps = (train_image_caption.shape[0]) // NEW_NUMBER_PICS_PER_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023403,
     "status": "ok",
     "timestamp": 1619109711165,
     "user": {
      "displayName": "Gpu User",
      "photoUrl": "",
      "userId": "05020043369902705889"
     },
     "user_tz": -330
    },
    "id": "pguVVNkRZZiO",
    "outputId": "5ce364a9-ee13-4830-97d8-8b1f90f0afa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 101s 101ms/step - loss: 2.3673\n",
      "1000/1000 [==============================] - 100s 100ms/step - loss: 2.3298\n",
      "1000/1000 [==============================] - 101s 101ms/step - loss: 2.3098\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2981\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2886\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2813\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2746\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2692\n",
      "1000/1000 [==============================] - 105s 104ms/step - loss: 2.2648\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 2.2580\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "for i in range(NEW_EPOCHS):\n",
    "\tgenerator = data_generator(train_image_caption, train_image_feature, wordtoix, max_caption_length, vocab_size, NEW_NUMBER_PICS_PER_BATCH)\n",
    "\tmodel.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "\tmodel.save(target_path + 'model_' + str(EPOCHS + i) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNp6gJwDd7iwpMCHl79/pAp",
   "name": "script_training_GColab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
